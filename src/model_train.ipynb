{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f763f168",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is the pipeline in charge of the bge-base-en-1.5v mode fine-tune. In this notebook what I'll do is the following:\n",
    "1. download train and validation data from the previous step from S3\n",
    "2. fine-tune the model for a couple of rounds\n",
    "3. compare the fine-tuned model with other versions of the same model (to do so I create a faiss index for each and run a serach of 10 chunks per query to then calculate several metrics)\n",
    "4. save the embeddings generated by the fine-tuned embedding model to OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc6e1b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cd67c8-2e3e-4f74-a5d6-b42d1f8974aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:27:07.086476Z",
     "iopub.status.busy": "2025-07-11T23:27:07.086171Z",
     "iopub.status.idle": "2025-07-11T23:27:08.571457Z",
     "shell.execute_reply": "2025-07-11T23:27:08.570845Z",
     "shell.execute_reply.started": "2025-07-11T23:27:07.086459Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -r model_training/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81222938-1a06-4b75-884d-b44d6e8be2a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:27:08.573067Z",
     "iopub.status.busy": "2025-07-11T23:27:08.572571Z",
     "iopub.status.idle": "2025-07-11T23:27:10.274604Z",
     "shell.execute_reply": "2025-07-11T23:27:10.274053Z",
     "shell.execute_reply.started": "2025-07-11T23:27:08.573045Z"
    }
   },
   "outputs": [],
   "source": [
    "from general_utils import load_config\n",
    "import torch\n",
    "\n",
    "CONFIG = load_config()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1522f3d2-e83d-447d-9d19-7d834454333e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:27:10.275776Z",
     "iopub.status.busy": "2025-07-11T23:27:10.275437Z",
     "iopub.status.idle": "2025-07-11T23:27:10.377173Z",
     "shell.execute_reply": "2025-07-11T23:27:10.376698Z",
     "shell.execute_reply.started": "2025-07-11T23:27:10.275757Z"
    }
   },
   "outputs": [],
   "source": [
    "from general_utils import S3Manager\n",
    "s3_client = S3Manager.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4023a75d-14ea-4dd4-a936-338d93a65f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:27:10.377796Z",
     "iopub.status.busy": "2025-07-11T23:27:10.377655Z",
     "iopub.status.idle": "2025-07-11T23:27:12.829443Z",
     "shell.execute_reply": "2025-07-11T23:27:12.828954Z",
     "shell.execute_reply.started": "2025-07-11T23:27:10.377781Z"
    }
   },
   "outputs": [],
   "source": [
    "S3Manager.download_files(\n",
    "    s3_client,\n",
    "    'model_training/data',\n",
    "     [\"training.json\",\n",
    "     \"test_queries.jsonl\",\n",
    "     \"corpus.jsonl\",\n",
    "     \"test_qrels.jsonl\"\n",
    "    ],\n",
    "    \"medical-qa-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55c781-3fd9-4bf8-982d-5bf0c9b10dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T22:13:26.773806Z",
     "iopub.status.busy": "2025-07-11T22:13:26.773541Z",
     "iopub.status.idle": "2025-07-11T22:13:26.779107Z",
     "shell.execute_reply": "2025-07-11T22:13:26.778412Z",
     "shell.execute_reply.started": "2025-07-11T22:13:26.773788Z"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062078b",
   "metadata": {},
   "source": [
    "# Fine tuning\n",
    "Will utilize the FlagEmbedding library implementation of the tuning pipeline, as it it suggested by the model's developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38801a66-c244-4723-b841-8980e1aef5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:27:12.830563Z",
     "iopub.status.busy": "2025-07-11T23:27:12.830386Z",
     "iopub.status.idle": "2025-07-11T23:44:27.411829Z",
     "shell.execute_reply": "2025-07-11T23:44:27.411305Z",
     "shell.execute_reply.started": "2025-07-11T23:27:12.830547Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchrun --nproc_per_node 1 -m FlagEmbedding.finetune.embedder.encoder_only.base --model_name_or_path BAAI/bge-base-en-v1.5 --train_data model_training/data/training.json --query_instruction_for_retrieval Represent this sentence for searching relevant passages: --output_dir model_training/model --learning_rate 1e-05 --fp16 --num_train_epochs 1 --per_device_train_batch_size 8 --query_max_len 256 --passage_max_len 512 --warmup_ratio 0.05 --normalize_embeddings True --logging_steps 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 23:27:17.955527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752276437.971267    2309 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752276437.976325    2309 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-11 23:27:17.991838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "07/11/2025 23:27:21 - WARNING - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n",
      "07/11/2025 23:27:21 - INFO - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Training/evaluation parameters AbsEmbedderTrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "fix_position_embedding=False,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "kd_loss_type=kl_div,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=model_training/model/runs/Jul11_23-27-21_default,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "negatives_cross_device=False,\n",
      "no_cuda=False,\n",
      "normalize_embeddings=True,\n",
      "num_train_epochs=1.0,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=model_training/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['mlflow', 'tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=model_training/model,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sentence_pooling_method=cls,\n",
      "skip_memory_metrics=True,\n",
      "sub_batch_size=None,\n",
      "temperature=0.02,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "07/11/2025 23:27:21 - INFO - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Model parameters AbsEmbedderModelArguments(model_name_or_path='BAAI/bge-base-en-v1.5', config_name=None, tokenizer_name=None, cache_dir=None, trust_remote_code=False, token=None)\n",
      "07/11/2025 23:27:21 - INFO - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Data parameters AbsEmbedderDataArguments(train_data=['model_training/data/training.json'], cache_path=None, train_group_size=8, query_max_len=256, passage_max_len=512, pad_to_multiple_of=None, max_example_num_per_dataset=100000000, query_instruction_for_retrieval='Represent this sentence for searching relevant passages:', query_instruction_format='{}{}', knowledge_distillation=False, passage_instruction_for_retrieval=None, passage_instruction_format='{}{}', shuffle_ratio=0.0, same_dataset_within_batch=False, small_threshold=0, drop_threshold=0)\n",
      "07/11/2025 23:27:22 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.runner -   Config: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "07/11/2025 23:27:22 - INFO - FlagEmbedding.abc.finetune.embedder.AbsDataset -   loading data from model_training/data/training.json ...\n",
      "Generating train split: 11980 examples [00:00, 14239.44 examples/s]\n",
      "/opt/conda/lib/python3.12/site-packages/FlagEmbedding/finetune/embedder/encoder_only/base/runner.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `EncoderOnlyEmbedderTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = EncoderOnlyEmbedderTrainer(\n",
      "  0%|          | 0/1498 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "  1%|          | 10/1498 [00:06<16:17,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2228, 'grad_norm': 0.2872343063354492, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 20/1498 [00:13<16:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4406, 'grad_norm': 0.5305854082107544, 'learning_rate': 2.133333333333334e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1498 [00:19<15:59,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.383, 'grad_norm': 4.104724407196045, 'learning_rate': 3.4666666666666672e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1498 [00:26<15:51,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2743, 'grad_norm': 12.460972785949707, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 50/1498 [00:33<15:42,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1724, 'grad_norm': 0.3199245035648346, 'learning_rate': 6.133333333333334e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 60/1498 [00:39<15:37,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3378, 'grad_norm': 0.15537141263484955, 'learning_rate': 7.4666666666666675e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 70/1498 [00:46<15:28,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0934, 'grad_norm': 14.955554962158203, 'learning_rate': 8.8e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 80/1498 [00:52<15:04,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0784, 'grad_norm': 15.120832443237305, 'learning_rate': 9.992972593113141e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 90/1498 [00:58<15:10,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0411, 'grad_norm': 0.9340715408325195, 'learning_rate': 9.922698524244555e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 100/1498 [01:05<15:10,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0061, 'grad_norm': 0.02038661390542984, 'learning_rate': 9.852424455375968e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 110/1498 [01:11<15:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0494, 'grad_norm': 0.20235000550746918, 'learning_rate': 9.782150386507379e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 120/1498 [01:18<14:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0057, 'grad_norm': 0.17647592723369598, 'learning_rate': 9.711876317638792e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 130/1498 [01:25<14:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1015, 'grad_norm': 1.0885107517242432, 'learning_rate': 9.641602248770204e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 140/1498 [01:31<14:45,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0088, 'grad_norm': 0.022232770919799805, 'learning_rate': 9.571328179901617e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 150/1498 [01:38<14:40,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1201, 'grad_norm': 12.321647644042969, 'learning_rate': 9.50105411103303e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 160/1498 [01:44<14:31,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0237, 'grad_norm': 0.2354845106601715, 'learning_rate': 9.430780042164443e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 170/1498 [01:51<14:25,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'grad_norm': 0.3331996500492096, 'learning_rate': 9.360505973295854e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 180/1498 [01:57<14:21,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0686, 'grad_norm': 28.511619567871094, 'learning_rate': 9.290231904427267e-06, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 190/1498 [02:04<14:13,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.015, 'grad_norm': 0.08075923472642899, 'learning_rate': 9.219957835558679e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 200/1498 [02:10<14:06,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0788, 'grad_norm': 0.0035928403958678246, 'learning_rate': 9.149683766690092e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 210/1498 [02:17<13:44,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0464, 'grad_norm': 1.007736086845398, 'learning_rate': 9.079409697821505e-06, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 220/1498 [02:23<13:52,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0317, 'grad_norm': 0.02787395939230919, 'learning_rate': 9.009135628952918e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 230/1498 [02:30<13:47,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0139, 'grad_norm': 0.0015129104722291231, 'learning_rate': 8.93886156008433e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 240/1498 [02:36<13:39,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0559, 'grad_norm': 0.14703983068466187, 'learning_rate': 8.868587491215742e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 250/1498 [02:43<13:35,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0048, 'grad_norm': 0.1100415363907814, 'learning_rate': 8.798313422347154e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 260/1498 [02:49<13:27,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0341, 'grad_norm': 13.640917778015137, 'learning_rate': 8.728039353478567e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 270/1498 [02:56<13:22,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0633, 'grad_norm': 0.00011624133912846446, 'learning_rate': 8.657765284609978e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 280/1498 [03:02<13:13,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0344, 'grad_norm': 0.8813758492469788, 'learning_rate': 8.587491215741393e-06, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 290/1498 [03:09<13:06,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.004, 'grad_norm': 0.513365626335144, 'learning_rate': 8.517217146872804e-06, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 300/1498 [03:15<12:56,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0438, 'grad_norm': 0.002510434715077281, 'learning_rate': 8.446943078004218e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 310/1498 [03:22<12:55,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0208, 'grad_norm': 1.275662899017334, 'learning_rate': 8.376669009135629e-06, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 320/1498 [03:28<12:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0832, 'grad_norm': 0.005666928365826607, 'learning_rate': 8.306394940267042e-06, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 330/1498 [03:35<12:42,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0027, 'grad_norm': 0.0005533059593290091, 'learning_rate': 8.236120871398453e-06, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 340/1498 [03:42<12:34,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0842, 'grad_norm': 0.03399350866675377, 'learning_rate': 8.165846802529868e-06, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 350/1498 [03:48<12:29,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'grad_norm': 0.0014170610811561346, 'learning_rate': 8.09557273366128e-06, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 360/1498 [03:55<12:23,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.024806996807456017, 'learning_rate': 8.025298664792693e-06, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 370/1498 [04:01<12:15,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0689, 'grad_norm': 4.044215679168701, 'learning_rate': 7.955024595924104e-06, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 380/1498 [04:08<12:09,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0275, 'grad_norm': 0.0018002022989094257, 'learning_rate': 7.884750527055517e-06, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 390/1498 [04:14<12:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0842, 'grad_norm': 4.649872779846191, 'learning_rate': 7.814476458186929e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 400/1498 [04:21<11:54,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0275, 'grad_norm': 0.022798078134655952, 'learning_rate': 7.744202389318343e-06, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 410/1498 [04:27<11:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0041, 'grad_norm': 1.2741225957870483, 'learning_rate': 7.673928320449755e-06, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 420/1498 [04:34<11:44,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0116, 'grad_norm': 0.00047184681170620024, 'learning_rate': 7.603654251581167e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 430/1498 [04:40<11:37,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0891, 'grad_norm': 0.07220727205276489, 'learning_rate': 7.533380182712579e-06, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 440/1498 [04:47<11:30,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.18373744189739227, 'learning_rate': 7.463106113843992e-06, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 450/1498 [04:53<11:22,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0489, 'grad_norm': 2.5354275703430176, 'learning_rate': 7.3928320449754046e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 460/1498 [05:00<11:16,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0402, 'grad_norm': 14.390166282653809, 'learning_rate': 7.322557976106818e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 470/1498 [05:06<11:10,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0295, 'grad_norm': 0.06840209662914276, 'learning_rate': 7.25228390723823e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 480/1498 [05:13<11:04,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.012, 'grad_norm': 0.0005931578925810754, 'learning_rate': 7.182009838369642e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 490/1498 [05:19<10:57,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0043, 'grad_norm': 0.029638569802045822, 'learning_rate': 7.111735769501054e-06, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 500/1498 [05:26<10:51,  1.53it/s]07/11/2025 23:32:52 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to model_training/model/checkpoint-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0062, 'grad_norm': 0.01664602942764759, 'learning_rate': 7.041461700632467e-06, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      " 34%|███▍      | 510/1498 [05:44<13:07,  1.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0531, 'grad_norm': 0.0051517244428396225, 'learning_rate': 6.97118763176388e-06, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 520/1498 [05:51<10:42,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0731, 'grad_norm': 1.578456794959493e-05, 'learning_rate': 6.900913562895292e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 530/1498 [05:58<10:29,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0354, 'grad_norm': 0.008438973687589169, 'learning_rate': 6.830639494026705e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 540/1498 [06:04<10:23,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0567, 'grad_norm': 0.3208337128162384, 'learning_rate': 6.760365425158117e-06, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 550/1498 [06:11<10:19,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0172, 'grad_norm': 0.8457298278808594, 'learning_rate': 6.6900913562895295e-06, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 560/1498 [06:17<10:07,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0555, 'grad_norm': 0.0037350100465118885, 'learning_rate': 6.619817287420942e-06, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 570/1498 [06:24<10:04,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.063, 'grad_norm': 0.024603016674518585, 'learning_rate': 6.549543218552354e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 580/1498 [06:30<09:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0011, 'grad_norm': 0.8704374432563782, 'learning_rate': 6.479269149683767e-06, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 590/1498 [06:37<09:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0079, 'grad_norm': 0.12570367753505707, 'learning_rate': 6.40899508081518e-06, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 600/1498 [06:43<09:44,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0347, 'grad_norm': 1.631155252456665, 'learning_rate': 6.338721011946592e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 610/1498 [06:50<09:38,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.04360812157392502, 'learning_rate': 6.268446943078005e-06, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 620/1498 [06:56<09:32,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0653, 'grad_norm': 24.29164695739746, 'learning_rate': 6.198172874209417e-06, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 630/1498 [07:03<09:25,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0132, 'grad_norm': 0.0032785367220640182, 'learning_rate': 6.127898805340829e-06, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 640/1498 [07:09<09:17,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0295, 'grad_norm': 0.0019707975443452597, 'learning_rate': 6.057624736472241e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 650/1498 [07:16<09:13,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.002090967958793044, 'learning_rate': 5.987350667603655e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 660/1498 [07:22<09:05,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0433, 'grad_norm': 7.764810288790613e-05, 'learning_rate': 5.9170765987350676e-06, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 670/1498 [07:29<09:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0206, 'grad_norm': 0.002593463519588113, 'learning_rate': 5.84680252986648e-06, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 680/1498 [07:35<08:52,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0075, 'grad_norm': 2.8137617111206055, 'learning_rate': 5.776528460997892e-06, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 690/1498 [07:42<08:43,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'grad_norm': 0.08308595418930054, 'learning_rate': 5.706254392129304e-06, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 700/1498 [07:48<08:41,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0187, 'grad_norm': 0.02304450236260891, 'learning_rate': 5.6359803232607165e-06, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 710/1498 [07:55<08:34,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0053, 'grad_norm': 0.5275506973266602, 'learning_rate': 5.5657062543921305e-06, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 720/1498 [08:01<08:27,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0126, 'grad_norm': 0.0021512776147574186, 'learning_rate': 5.495432185523543e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 730/1498 [08:08<08:19,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0427, 'grad_norm': 5.724028960685246e-05, 'learning_rate': 5.425158116654955e-06, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 740/1498 [08:14<08:14,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0385, 'grad_norm': 26.72345733642578, 'learning_rate': 5.354884047786367e-06, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 750/1498 [08:21<08:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1036, 'grad_norm': 22.272626876831055, 'learning_rate': 5.2846099789177794e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 760/1498 [08:27<08:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0016, 'grad_norm': 0.03281472250819206, 'learning_rate': 5.214335910049192e-06, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 770/1498 [08:34<07:55,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0245, 'grad_norm': 0.0003843794693239033, 'learning_rate': 5.144061841180604e-06, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 780/1498 [08:40<07:46,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0021, 'grad_norm': 3.085937023162842, 'learning_rate': 5.073787772312018e-06, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 790/1498 [08:47<07:42,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0181, 'grad_norm': 0.03226613998413086, 'learning_rate': 5.00351370344343e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 800/1498 [08:53<07:34,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0081, 'grad_norm': 0.0007956930203363299, 'learning_rate': 4.933239634574842e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 810/1498 [09:00<07:29,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'grad_norm': 0.1493021845817566, 'learning_rate': 4.862965565706255e-06, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 820/1498 [09:06<07:21,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0235, 'grad_norm': 0.026879537850618362, 'learning_rate': 4.792691496837668e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 830/1498 [09:13<07:15,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0228, 'grad_norm': 0.3993976414203644, 'learning_rate': 4.72241742796908e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 840/1498 [09:20<07:08,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.0015805925941094756, 'learning_rate': 4.652143359100492e-06, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 850/1498 [09:26<07:02,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0159, 'grad_norm': 0.0005396092310547829, 'learning_rate': 4.581869290231905e-06, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 860/1498 [09:33<06:56,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0235, 'grad_norm': 11.488312721252441, 'learning_rate': 4.5115952213633175e-06, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 870/1498 [09:39<06:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'grad_norm': 0.00032758706947788596, 'learning_rate': 4.44132115249473e-06, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 880/1498 [09:46<06:43,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'grad_norm': 0.0004016447637695819, 'learning_rate': 4.371047083626142e-06, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 890/1498 [09:52<06:37,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0059, 'grad_norm': 0.00017022380779962987, 'learning_rate': 4.300773014757555e-06, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 900/1498 [09:59<06:30,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0086, 'grad_norm': 0.06104109436273575, 'learning_rate': 4.230498945888967e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 910/1498 [10:05<06:23,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0559, 'grad_norm': 0.00017051940085366368, 'learning_rate': 4.1602248770203795e-06, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 920/1498 [10:12<06:17,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0665, 'grad_norm': 3.943494903069222e-06, 'learning_rate': 4.089950808151793e-06, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 930/1498 [10:18<06:11,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0523, 'grad_norm': 0.003912900574505329, 'learning_rate': 4.019676739283205e-06, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 940/1498 [10:25<06:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0002, 'grad_norm': 0.0022401735186576843, 'learning_rate': 3.949402670414617e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 950/1498 [10:31<05:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0336, 'grad_norm': 1.3069478273391724, 'learning_rate': 3.87912860154603e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 960/1498 [10:38<05:50,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0222, 'grad_norm': 0.010462482459843159, 'learning_rate': 3.8088545326774424e-06, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 970/1498 [10:44<05:45,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0179, 'grad_norm': 0.10365218669176102, 'learning_rate': 3.7385804638088547e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 980/1498 [10:51<05:37,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0711, 'grad_norm': 6.747337341308594, 'learning_rate': 3.6683063949402673e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 990/1498 [10:57<05:31,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0563, 'grad_norm': 0.15940849483013153, 'learning_rate': 3.59803232607168e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1000/1498 [11:04<05:24,  1.53it/s]07/11/2025 23:38:30 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to model_training/model/checkpoint-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'grad_norm': 0.007190367206931114, 'learning_rate': 3.5277582572030923e-06, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 1010/1498 [11:23<06:30,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.038, 'grad_norm': 5.659230709075928, 'learning_rate': 3.457484188334505e-06, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1020/1498 [11:29<05:13,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'grad_norm': 0.0004365237837191671, 'learning_rate': 3.3872101194659176e-06, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1030/1498 [11:36<05:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'grad_norm': 0.0074431621469557285, 'learning_rate': 3.31693605059733e-06, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1040/1498 [11:42<04:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0503, 'grad_norm': 0.0005899499519728124, 'learning_rate': 3.2466619817287425e-06, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1050/1498 [11:49<04:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.021, 'grad_norm': 0.013082698918879032, 'learning_rate': 3.1763879128601547e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1060/1498 [11:55<04:46,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0357, 'grad_norm': 0.004151010420173407, 'learning_rate': 3.1061138439915674e-06, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1070/1498 [12:02<04:38,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'grad_norm': 0.030608082190155983, 'learning_rate': 3.03583977512298e-06, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1080/1498 [12:08<04:29,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0226, 'grad_norm': 0.014499650336802006, 'learning_rate': 2.9655657062543923e-06, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1090/1498 [12:15<04:26,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0011, 'grad_norm': 0.018620064482092857, 'learning_rate': 2.895291637385805e-06, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1100/1498 [12:21<04:19,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.031, 'grad_norm': 0.010325251147150993, 'learning_rate': 2.8250175685172176e-06, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1110/1498 [12:28<04:13,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0312, 'grad_norm': 0.02561090886592865, 'learning_rate': 2.75474349964863e-06, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1120/1498 [12:34<04:06,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0603, 'grad_norm': 0.012307639233767986, 'learning_rate': 2.684469430780042e-06, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1130/1498 [12:41<03:59,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0029, 'grad_norm': 1.2785083055496216, 'learning_rate': 2.6141953619114548e-06, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1140/1498 [12:47<03:52,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0064, 'grad_norm': 3.6805906295776367, 'learning_rate': 2.5439212930428674e-06, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1150/1498 [12:54<03:47,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0181, 'grad_norm': 0.0004166977305430919, 'learning_rate': 2.4736472241742797e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1160/1498 [13:01<03:40,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'grad_norm': 0.0038504544645547867, 'learning_rate': 2.4033731553056924e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1170/1498 [13:07<03:34,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.029274195432662964, 'learning_rate': 2.333099086437105e-06, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1180/1498 [13:14<03:27,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0442, 'grad_norm': 0.12505193054676056, 'learning_rate': 2.2628250175685173e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1190/1498 [13:20<03:20,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.024, 'grad_norm': 0.6312962770462036, 'learning_rate': 2.19255094869993e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1200/1498 [13:27<03:14,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0362, 'grad_norm': 4.650592745747417e-05, 'learning_rate': 2.122276879831342e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1210/1498 [13:33<03:08,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0169, 'grad_norm': 4.689202785491943, 'learning_rate': 2.052002810962755e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 1220/1498 [13:40<03:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0713, 'grad_norm': 0.0010695622768253088, 'learning_rate': 1.9817287420941675e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1230/1498 [13:46<02:53,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0207, 'grad_norm': 0.00016365396731998771, 'learning_rate': 1.9114546732255797e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1240/1498 [13:53<02:48,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0017, 'grad_norm': 0.0009108020458370447, 'learning_rate': 1.8411806043569924e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1250/1498 [13:59<02:42,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0018, 'grad_norm': 0.000542948953807354, 'learning_rate': 1.770906535488405e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1260/1498 [14:06<02:35,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0178, 'grad_norm': 11.916707992553711, 'learning_rate': 1.7006324666198173e-06, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1270/1498 [14:12<02:28,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'grad_norm': 0.1760421097278595, 'learning_rate': 1.63035839775123e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1280/1498 [14:19<02:21,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0315, 'grad_norm': 8.214435577392578, 'learning_rate': 1.5600843288826426e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1290/1498 [14:25<02:15,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0021, 'grad_norm': 0.005861240904778242, 'learning_rate': 1.4898102600140549e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1300/1498 [14:32<02:09,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0339, 'grad_norm': 0.0013637726660817862, 'learning_rate': 1.4195361911454676e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1310/1498 [14:38<02:02,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.027, 'grad_norm': 5.392150796978967e-06, 'learning_rate': 1.3492621222768798e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1320/1498 [14:45<01:56,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0409, 'grad_norm': 0.14365530014038086, 'learning_rate': 1.2789880534082925e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1330/1498 [14:51<01:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.005, 'grad_norm': 8.911045733839273e-05, 'learning_rate': 1.208713984539705e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1340/1498 [14:58<01:43,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0254, 'grad_norm': 13.946990013122559, 'learning_rate': 1.1384399156711176e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1350/1498 [15:05<01:36,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.033, 'grad_norm': 0.0004055551835335791, 'learning_rate': 1.06816584680253e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1360/1498 [15:11<01:30,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0197, 'grad_norm': 3.191890239715576, 'learning_rate': 9.978917779339425e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 1370/1498 [15:18<01:23,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0386, 'grad_norm': 0.012581920251250267, 'learning_rate': 9.27617709065355e-07, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1380/1498 [15:24<01:16,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0201, 'grad_norm': 6.996563911437988, 'learning_rate': 8.573436401967675e-07, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1390/1498 [15:31<01:10,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'grad_norm': 0.0003349929756950587, 'learning_rate': 7.8706957132818e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1400/1498 [15:37<01:04,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'grad_norm': 0.0004560559755191207, 'learning_rate': 7.167955024595925e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1410/1498 [15:44<00:57,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0079, 'grad_norm': 1.229417324066162, 'learning_rate': 6.46521433591005e-07, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1420/1498 [15:50<00:50,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0471, 'grad_norm': 0.0058892397210001945, 'learning_rate': 5.762473647224174e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1430/1498 [15:57<00:44,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0009, 'grad_norm': 0.02863295190036297, 'learning_rate': 5.0597329585383e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1440/1498 [16:03<00:37,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0463, 'grad_norm': 6.582356929779053, 'learning_rate': 4.356992269852425e-07, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1450/1498 [16:10<00:31,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0379, 'grad_norm': 0.04216351732611656, 'learning_rate': 3.65425158116655e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1460/1498 [16:16<00:24,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0326, 'grad_norm': 0.019962292164564133, 'learning_rate': 2.951510892480675e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1470/1498 [16:23<00:18,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0268, 'grad_norm': 15.850833892822266, 'learning_rate': 2.2487702037948e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1480/1498 [16:29<00:11,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0932, 'grad_norm': 0.00018782119150273502, 'learning_rate': 1.5460295151089248e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1490/1498 [16:36<00:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0028, 'grad_norm': 0.0001386524672852829, 'learning_rate': 8.432888264230499e-08, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1498/1498 [16:41<00:00,  1.81it/s]07/11/2025 23:44:07 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to model_training/model/checkpoint-1498\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "100%|██████████| 1498/1498 [16:53<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1013.7359, 'train_samples_per_second': 11.818, 'train_steps_per_second': 1.478, 'train_loss': 0.039941850994951095, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1498/1498 [16:54<00:00,  1.48it/s]\n",
      "07/11/2025 23:44:20 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to model_training/model\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[rank0]:[W711 23:44:25.063887746 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "lr = float(CONFIG['LR'])\n",
    "epochs = int(CONFIG['EPOCHS'])\n",
    "warmup = float(CONFIG['WARMUP_RATIO'])\n",
    "batch_size = int(CONFIG['BATCH_SIZE'])\n",
    "embedding_model = CONFIG['EMBEDDING_MODEL']\n",
    "query_instruction = CONFIG[\"QUERY_INSTRUCTION_AT_RETRIEVAL\"]\n",
    "\n",
    "cmd = [\n",
    "    \"torchrun\", \"--nproc_per_node\", \"1\",\n",
    "    \"-m\", \"FlagEmbedding.finetune.embedder.encoder_only.base\",\n",
    "    \"--model_name_or_path\", f\"BAAI/{embedding_model}\",\n",
    "    \"--train_data\", \"model_training/data/training.json\",\n",
    "    \"--query_instruction_for_retrieval\", query_instruction,\n",
    "    \"--output_dir\", \"model_training/model\",\n",
    "    \"--learning_rate\", str(lr),\n",
    "    \"--fp16\",\n",
    "    \"--num_train_epochs\", str(epochs),\n",
    "    \"--per_device_train_batch_size\", str(batch_size),\n",
    "    \"--query_max_len\", \"256\",\n",
    "    \"--passage_max_len\", \"512\",\n",
    "    \"--warmup_ratio\", str(warmup),\n",
    "    \"--normalize_embeddings\", \"True\",\n",
    "    \"--logging_steps\", \"10\",\n",
    "]\n",
    "\n",
    "print(\" \".join(cmd))\n",
    "result = subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2943fbf-1c54-491f-91db-930ba9b7314d",
   "metadata": {},
   "source": [
    "Save the model files to S3 for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbe2043-e0ac-42d9-ab94-d357b25883f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:44:34.713206Z",
     "iopub.status.busy": "2025-07-11T23:44:34.712818Z",
     "iopub.status.idle": "2025-07-11T23:44:36.644087Z",
     "shell.execute_reply": "2025-07-11T23:44:36.643472Z",
     "shell.execute_reply.started": "2025-07-11T23:44:34.713190Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk('model_training/model/'):\n",
    "    if root=='model_training/model/':\n",
    "        for file in files:\n",
    "            file_list.append(file)\n",
    "\n",
    "S3Manager.upload_bulk(\n",
    "    s3_client,\n",
    "    'model_training/model/',\n",
    "    file_list,\n",
    "    \"medical-qa-data\",\n",
    "    \"finetuned_model/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9157f7-374a-4180-bca7-78c80c3cbbe3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluate\n",
    "First, I'll load and generate the needed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d61039-325b-4a37-842d-69ccb41eb41a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:44:39.189036Z",
     "iopub.status.busy": "2025-07-11T23:44:39.188699Z",
     "iopub.status.idle": "2025-07-11T23:44:40.841608Z",
     "shell.execute_reply": "2025-07-11T23:44:40.841054Z",
     "shell.execute_reply.started": "2025-07-11T23:44:39.189020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59343e21337c45458ad3880b25f43fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090481aeccb447a4bc9facd6870a528f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c40810fcdd3464594249688d08e2d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "queries = load_dataset(\"json\", data_files=\"model_training/data/test_queries.jsonl\")[\"train\"]\n",
    "corpus = load_dataset(\"json\", data_files=\"model_training/data/corpus.jsonl\")[\"train\"]\n",
    "qrels = load_dataset(\"json\", data_files=\"model_training/data/test_qrels.jsonl\")[\"train\"]\n",
    "\n",
    "queries_text = queries[\"text\"]\n",
    "corpus_text = [text for text in corpus[\"text\"]]\n",
    "qrels_dict = {}\n",
    "for line in qrels:\n",
    "    if line['qid'] not in qrels_dict:\n",
    "        qrels_dict[str(line['qid'])] = {}\n",
    "    for doc in line['docid']:\n",
    "        qrels_dict[str(line['qid'])][str(doc)] = line['relevance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958732f",
   "metadata": {},
   "source": [
    "I will now load the needed metrics from FlagEmbedding, the wrapper to load models with the library and a custom made wrapper \"Validator\" in charge of processing the needed steps to embed and index (in faiss) the queries and corpus, to then perform the semantic search to bring the top 10 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bac51a05-eb04-4633-9e3c-b15d38c0a9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:45:10.734868Z",
     "iopub.status.busy": "2025-07-11T23:45:10.734384Z",
     "iopub.status.idle": "2025-07-11T23:45:12.406582Z",
     "shell.execute_reply": "2025-07-11T23:45:12.405931Z",
     "shell.execute_reply.started": "2025-07-11T23:45:10.734849Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q opensearch_py==3.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b16910-a7d2-4837-9525-9f8faabe9b48",
   "metadata": {},
   "source": [
    "As we will use this retrieval without any reranking, I will focus my analysis to 1 and 3 k (nevertheless I compute 5 & 10 too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2a11d8-a368-4efd-a4b8-7689cba335e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:47:17.446064Z",
     "iopub.status.busy": "2025-07-11T23:47:17.445802Z",
     "iopub.status.idle": "2025-07-11T23:47:17.449121Z",
     "shell.execute_reply": "2025-07-11T23:47:17.448616Z",
     "shell.execute_reply.started": "2025-07-11T23:47:17.446047Z"
    }
   },
   "outputs": [],
   "source": [
    "from FlagEmbedding.abc.evaluation.utils import evaluate_metrics, evaluate_mrr\n",
    "from FlagEmbedding import FlagModel\n",
    "from model_training.utils import Validator\n",
    "\n",
    "k_values = [1, 3, 5, 10]\n",
    "raw_name = f\"BAAI/{CONFIG['EMBEDDING_MODEL']}\"\n",
    "finetuned_path = \"model_training/model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5db5bc-7045-4f3a-81f7-a88120e28c9b",
   "metadata": {},
   "source": [
    "#### Raw model w/o prompting\n",
    "Let's 1st check the stats for the raw model without any pormpting technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ec6ad8-bb2b-4eac-897d-584baf7234b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:47:21.014192Z",
     "iopub.status.busy": "2025-07-11T23:47:21.013864Z",
     "iopub.status.idle": "2025-07-11T23:48:03.242502Z",
     "shell.execute_reply": "2025-07-11T23:48:03.241931Z",
     "shell.execute_reply.started": "2025-07-11T23:47:21.014176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 12/12 [00:00<00:00, 31.16it/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 12/12 [00:00<00:00, 40.79it/s]\n",
      "pre tokenize: 100%|██████████| 74/74 [00:04<00:00, 15.96it/s]\n",
      "Inference Embeddings: 100%|██████████| 74/74 [00:21<00:00,  3.48it/s]\n",
      "100%|██████████| 94/94 [00:01<00:00, 91.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'NDCG@1': 0.62016, 'NDCG@3': 0.6928, 'NDCG@5': 0.71499, 'NDCG@10': 0.73232})\n",
      "defaultdict(<class 'list'>, {'MAP@1': 0.55161, 'MAP@3': 0.64691, 'MAP@5': 0.664, 'MAP@10': 0.67436})\n",
      "defaultdict(<class 'list'>, {'Recall@1': 0.55161, 'Recall@3': 0.74314, 'Recall@5': 0.80182, 'Recall@10': 0.85531})\n",
      "defaultdict(<class 'list'>, {'P@1': 0.62016, 'P@3': 0.29194, 'P@5': 0.19339, 'P@10': 0.10621})\n",
      "defaultdict(<class 'list'>, {'MRR@1': 0.62016, 'MRR@3': 0.70572, 'MRR@5': 0.71795, 'MRR@10': 0.72384})\n"
     ]
    }
   ],
   "source": [
    "raw_model = FlagModel(\n",
    "    raw_name, \n",
    "    query_instruction_for_retrieval=\"\",\n",
    "    devices=[0],\n",
    "    use_fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "results, _ = Validator.search(raw_model, queries_text, corpus_text, queries)\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fcc0f-0732-4ec9-bbf4-57241ab6760e",
   "metadata": {},
   "source": [
    "We can see that the metrics @1 and @3 are standard for a model that hasn't been finetuned in out task nor is being used correctly as it's not preceeded by a prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484e1e4-aa24-46de-8b02-a462af7395be",
   "metadata": {},
   "source": [
    "### Raw model with prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16c62338-c838-43a3-a562-ae205209764d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:48:03.243523Z",
     "iopub.status.busy": "2025-07-11T23:48:03.243347Z",
     "iopub.status.idle": "2025-07-11T23:48:44.102171Z",
     "shell.execute_reply": "2025-07-11T23:48:44.101602Z",
     "shell.execute_reply.started": "2025-07-11T23:48:03.243508Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 12/12 [00:00<00:00, 109.04it/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 12/12 [00:00<00:00, 31.36it/s]\n",
      "pre tokenize: 100%|██████████| 74/74 [00:04<00:00, 15.98it/s]\n",
      "Inference Embeddings: 100%|██████████| 74/74 [00:21<00:00,  3.49it/s]\n",
      "100%|██████████| 94/94 [00:01<00:00, 92.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'NDCG@1': 0.63718, 'NDCG@3': 0.705, 'NDCG@5': 0.72482, 'NDCG@10': 0.74046})\n",
      "defaultdict(<class 'list'>, {'MAP@1': 0.56459, 'MAP@3': 0.65901, 'MAP@5': 0.67493, 'MAP@10': 0.68473})\n",
      "defaultdict(<class 'list'>, {'Recall@1': 0.56459, 'Recall@3': 0.75307, 'Recall@5': 0.80703, 'Recall@10': 0.85567})\n",
      "defaultdict(<class 'list'>, {'P@1': 0.63718, 'P@3': 0.29717, 'P@5': 0.19546, 'P@10': 0.10684})\n",
      "defaultdict(<class 'list'>, {'MRR@1': 0.63718, 'MRR@3': 0.7189, 'MRR@5': 0.73017, 'MRR@10': 0.7352})\n"
     ]
    }
   ],
   "source": [
    "prompted_raw_model = FlagModel(\n",
    "    raw_name, \n",
    "    query_instruction_for_retrieval=CONFIG['QUERY_INSTRUCTION_AT_RETRIEVAL'],\n",
    "    devices=[0],\n",
    "    use_fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "results, _ = Validator.search(prompted_raw_model, queries_text, corpus_text, queries)\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf422f3-50ff-4e02-b046-8ee763f78521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:52:50.877577Z",
     "iopub.status.busy": "2025-07-11T23:52:50.877286Z",
     "iopub.status.idle": "2025-07-11T23:52:50.882793Z",
     "shell.execute_reply": "2025-07-11T23:52:50.882039Z",
     "shell.execute_reply.started": "2025-07-11T23:52:50.877559Z"
    }
   },
   "source": [
    "When we add a prompt we see increases in the metrics, mostly @3, but let's check now our fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d21c56-6afb-4a18-9348-d3e2d1717ffd",
   "metadata": {},
   "source": [
    "### Finetuned model with prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac4cba10-3e08-4448-a317-eda3680afdd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:48:44.102960Z",
     "iopub.status.busy": "2025-07-11T23:48:44.102783Z",
     "iopub.status.idle": "2025-07-11T23:49:25.376178Z",
     "shell.execute_reply": "2025-07-11T23:49:25.375663Z",
     "shell.execute_reply.started": "2025-07-11T23:48:44.102945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 12/12 [00:00<00:00, 28.85it/s] \n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 12/12 [00:00<00:00, 31.20it/s]\n",
      "pre tokenize: 100%|██████████| 74/74 [00:04<00:00, 15.74it/s]\n",
      "Inference Embeddings: 100%|██████████| 74/74 [00:21<00:00,  3.48it/s]\n",
      "100%|██████████| 94/94 [00:01<00:00, 92.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'NDCG@1': 0.78605, 'NDCG@3': 0.82023, 'NDCG@5': 0.82805, 'NDCG@10': 0.83965})\n",
      "defaultdict(<class 'list'>, {'MAP@1': 0.70468, 'MAP@3': 0.7826, 'MAP@5': 0.79265, 'MAP@10': 0.80183})\n",
      "defaultdict(<class 'list'>, {'Recall@1': 0.70468, 'Recall@3': 0.84114, 'Recall@5': 0.86802, 'Recall@10': 0.90394})\n",
      "defaultdict(<class 'list'>, {'P@1': 0.78605, 'P@3': 0.33311, 'P@5': 0.21155, 'P@10': 0.11452})\n",
      "defaultdict(<class 'list'>, {'MRR@1': 0.78605, 'MRR@3': 0.84001, 'MRR@5': 0.84423, 'MRR@10': 0.84715})\n"
     ]
    }
   ],
   "source": [
    "ft_model = FlagModel(\n",
    "    finetuned_path, \n",
    "    query_instruction_for_retrieval=CONFIG['QUERY_INSTRUCTION_AT_RETRIEVAL'],\n",
    "    devices=[0],\n",
    "    use_fp16=True\n",
    ")\n",
    "\n",
    "results, corpus_embeddings = Validator.search(ft_model, queries_text, corpus_text, queries)\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3fa4e-c60d-4bd1-9151-e90421c537e8",
   "metadata": {},
   "source": [
    "We see that the metrics increased greatly (eg: NDCG@1 increased +20% and NDCG@3 +17%). We can say that the embedding fine tune worked correclty and we ended up with a decent model to be used in a RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8ce68-a16c-4c82-a5d0-e9e247f99308",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ingest into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1667c-e4f2-4a05-9ceb-b72e966a734b",
   "metadata": {},
   "source": [
    "Finally we will ingest our finetuned embeddings into opensearch so the can be used at inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c44a47e2-f40f-4e5b-bc65-e6374c37b869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:54:55.344763Z",
     "iopub.status.busy": "2025-07-11T23:54:55.344412Z",
     "iopub.status.idle": "2025-07-11T23:54:55.359959Z",
     "shell.execute_reply": "2025-07-11T23:54:55.359394Z",
     "shell.execute_reply.started": "2025-07-11T23:54:55.344746Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model_training.utils import OpenSearchManager\n",
    "index_name = 'embedding-finetuned-v1'\n",
    "host = CONFIG['OPENSEARCH_INDEX_URL'].removeprefix('https://').removesuffix('/'+index_name)\n",
    "opens_mngr = OpenSearchManager(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "894f55c5-d804-41a0-90b5-a8b5cd706b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:54:57.059097Z",
     "iopub.status.busy": "2025-07-11T23:54:57.058529Z",
     "iopub.status.idle": "2025-07-11T23:54:57.128892Z",
     "shell.execute_reply": "2025-07-11T23:54:57.128456Z",
     "shell.execute_reply.started": "2025-07-11T23:54:57.059078Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opensearch:PUT https://search-medical-qa-system-wllp2yik3gws7durfruiomvfky.us-east-2.es.amazonaws.com:443/embedding-finetuned-v1 [status:400 request:0.066s]\n",
      "WARNING:root:Index already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "opens_mngr.create_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "271f8f30-1376-412e-b7ff-aa37f54c000d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T23:55:00.374883Z",
     "iopub.status.busy": "2025-07-11T23:55:00.374390Z",
     "iopub.status.idle": "2025-07-11T23:55:00.377299Z",
     "shell.execute_reply": "2025-07-11T23:55:00.376802Z",
     "shell.execute_reply.started": "2025-07-11T23:55:00.374866Z"
    }
   },
   "outputs": [],
   "source": [
    "opens_mngr.bulk_ingestion(index_name, corpus_text, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d8ab1",
   "metadata": {},
   "source": [
    "Now we are ready to consume these vectors at inference time"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
