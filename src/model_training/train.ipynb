{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a3c3b0-b7bb-4676-87cf-f3c9226d511a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:36:49.053012Z",
     "iopub.status.busy": "2025-07-11T20:36:49.052754Z",
     "iopub.status.idle": "2025-07-11T20:36:57.349557Z",
     "shell.execute_reply": "2025-07-11T20:36:57.348896Z",
     "shell.execute_reply.started": "2025-07-11T20:36:49.052995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.2.4 requires onnxruntime<2,>=1.15.0, which is not installed.\n",
      "autogluon-multimodal 1.3.1 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "aiobotocore 2.21.1 requires botocore<1.37.2,>=1.37.0, but you have botocore 1.39.4 which is incompatible.\n",
      "autogluon-multimodal 1.3.1 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.52.4 which is incompatible.\n",
      "autogluon-timeseries 1.3.1 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.52.4 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.5 which is incompatible.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.1.7 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8657a202-6ac1-4ddd-81f9-2c29d43cfe54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T09:06:02.377050Z",
     "iopub.status.busy": "2025-07-11T09:06:02.376615Z",
     "iopub.status.idle": "2025-07-11T09:06:02.502791Z",
     "shell.execute_reply": "2025-07-11T09:06:02.502300Z",
     "shell.execute_reply.started": "2025-07-11T09:06:02.377031Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "boto3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a625a16b-4671-41b1-abd0-a8d0e423f843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:28:03.241405Z",
     "iopub.status.busy": "2025-07-11T08:28:03.241174Z",
     "iopub.status.idle": "2025-07-11T08:28:06.849357Z",
     "shell.execute_reply": "2025-07-11T08:28:06.848800Z",
     "shell.execute_reply.started": "2025-07-11T08:28:03.241380Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in [\"training.json\", \"test_queries.jsonl\", \"corpus.jsonl\", \"test_qrels.jsonl\"]:\n",
    "    boto3_client.download_file(\n",
    "        \"medical-qa-data\",\n",
    "        file,\n",
    "        f\"data/{file}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7766cb8-f0e5-4231-94aa-0534484ed51a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T17:18:53.985898Z",
     "iopub.status.busy": "2025-07-10T17:18:53.985144Z",
     "iopub.status.idle": "2025-07-10T17:18:53.992382Z",
     "shell.execute_reply": "2025-07-10T17:18:53.991426Z",
     "shell.execute_reply.started": "2025-07-10T17:18:53.985869Z"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30e5356-cdf3-41c0-80d3-cffc25e3cc45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:53:16.475119Z",
     "iopub.status.busy": "2025-07-11T08:53:16.474535Z",
     "iopub.status.idle": "2025-07-11T08:53:16.477742Z",
     "shell.execute_reply": "2025-07-11T08:53:16.477258Z",
     "shell.execute_reply.started": "2025-07-11T08:53:16.475100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82839f5-5e84-493a-8661-eada5e08b4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:53:18.455269Z",
     "iopub.status.busy": "2025-07-11T08:53:18.454898Z",
     "iopub.status.idle": "2025-07-11T09:01:19.945609Z",
     "shell.execute_reply": "2025-07-11T09:01:19.945056Z",
     "shell.execute_reply.started": "2025-07-11T08:53:18.455252Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 08:53:23.872102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752224003.888446    1948 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752224003.893843    1948 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-11 08:53:23.910035: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "07/11/2025 08:53:27 - WARNING - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n",
      "07/11/2025 08:53:27 - INFO - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Training/evaluation parameters AbsEmbedderTrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "fix_position_embedding=False,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "kd_loss_type=kl_div,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./model/runs/Jul11_08-53-26_default,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "negatives_cross_device=False,\n",
      "no_cuda=False,\n",
      "normalize_embeddings=True,\n",
      "num_train_epochs=1.0,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=20,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['mlflow', 'tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./model,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sentence_pooling_method=cls,\n",
      "skip_memory_metrics=True,\n",
      "sub_batch_size=None,\n",
      "temperature=0.02,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "07/11/2025 08:53:27 - INFO - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Model parameters AbsEmbedderModelArguments(model_name_or_path='BAAI/bge-small-en-v1.5', config_name=None, tokenizer_name=None, cache_dir=None, trust_remote_code=False, token=None)\n",
      "07/11/2025 08:53:27 - INFO - FlagEmbedding.abc.finetune.embedder.AbsRunner -   Data parameters AbsEmbedderDataArguments(train_data=['./data/training.json'], cache_path=None, train_group_size=8, query_max_len=256, passage_max_len=512, pad_to_multiple_of=None, max_example_num_per_dataset=100000000, query_instruction_for_retrieval='Represent this sentence for searching relevant passages: ', query_instruction_format='{}{}', knowledge_distillation=False, passage_instruction_for_retrieval=None, passage_instruction_format='{}{}', shuffle_ratio=0.0, same_dataset_within_batch=False, small_threshold=0, drop_threshold=0)\n",
      "07/11/2025 08:53:28 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.runner -   Config: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "07/11/2025 08:53:28 - INFO - FlagEmbedding.abc.finetune.embedder.AbsDataset -   loading data from ./data/training.json ...\n",
      "Generating train split: 11980 examples [00:00, 13325.20 examples/s]\n",
      "/opt/conda/lib/python3.12/site-packages/FlagEmbedding/finetune/embedder/encoder_only/base/runner.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `EncoderOnlyEmbedderTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = EncoderOnlyEmbedderTrainer(\n",
      "  0%|          | 0/599 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 10/599 [00:08<07:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4827, 'grad_norm': 10.808923721313477, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/599 [00:16<07:17,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5282, 'grad_norm': 7.718830585479736, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4724, 'grad_norm': 5.4362335205078125, 'learning_rate': 9e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 40/599 [00:31<07:03,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1884, 'grad_norm': 5.9627766609191895, 'learning_rate': 9.876977152899824e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.292, 'grad_norm': 8.9385347366333, 'learning_rate': 9.701230228471003e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1606, 'grad_norm': 7.1891093254089355, 'learning_rate': 9.52548330404218e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.156, 'grad_norm': 5.948652744293213, 'learning_rate': 9.349736379613358e-06, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 80/599 [01:01<06:32,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1634, 'grad_norm': 1.3794618844985962, 'learning_rate': 9.173989455184536e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0885, 'grad_norm': 5.9436936378479, 'learning_rate': 8.998242530755711e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1004, 'grad_norm': 2.6904990673065186, 'learning_rate': 8.822495606326889e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1539, 'grad_norm': 0.1965733766555786, 'learning_rate': 8.646748681898068e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.07, 'grad_norm': 5.492007255554199, 'learning_rate': 8.471001757469245e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1133, 'grad_norm': 2.0162806510925293, 'learning_rate': 8.295254833040423e-06, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0819, 'grad_norm': 0.821169912815094, 'learning_rate': 8.1195079086116e-06, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0692, 'grad_norm': 4.818043231964111, 'learning_rate': 7.943760984182778e-06, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1252, 'grad_norm': 7.660617828369141, 'learning_rate': 7.768014059753954e-06, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0946, 'grad_norm': 1.6915029287338257, 'learning_rate': 7.592267135325132e-06, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1035, 'grad_norm': 3.3077456951141357, 'learning_rate': 7.416520210896309e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 190/599 [02:25<05:10,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1307, 'grad_norm': 0.3849337100982666, 'learning_rate': 7.240773286467488e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0429, 'grad_norm': 3.342235565185547, 'learning_rate': 7.065026362038665e-06, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0763, 'grad_norm': 0.480345755815506, 'learning_rate': 6.889279437609843e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.102, 'grad_norm': 6.3089141845703125, 'learning_rate': 6.71353251318102e-06, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0366, 'grad_norm': 5.362974643707275, 'learning_rate': 6.537785588752197e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1042, 'grad_norm': 2.8537862300872803, 'learning_rate': 6.362038664323374e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1505, 'grad_norm': 4.953616142272949, 'learning_rate': 6.1862917398945525e-06, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 260/599 [03:18<04:17,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0376, 'grad_norm': 0.06980933248996735, 'learning_rate': 6.01054481546573e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1195, 'grad_norm': 7.703184127807617, 'learning_rate': 5.8347978910369074e-06, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0952, 'grad_norm': 12.174942016601562, 'learning_rate': 5.659050966608085e-06, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0643, 'grad_norm': 1.0440765619277954, 'learning_rate': 5.483304042179262e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1444, 'grad_norm': 8.91006851196289, 'learning_rate': 5.307557117750439e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0548, 'grad_norm': 0.3690200746059418, 'learning_rate': 5.131810193321617e-06, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0658, 'grad_norm': 0.3789636194705963, 'learning_rate': 4.956063268892795e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0334, 'grad_norm': 3.769681930541992, 'learning_rate': 4.780316344463972e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0705, 'grad_norm': 2.1211910247802734, 'learning_rate': 4.60456942003515e-06, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 350/599 [04:26<03:08,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0326, 'grad_norm': 0.7843189835548401, 'learning_rate': 4.428822495606327e-06, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0624, 'grad_norm': 4.132644176483154, 'learning_rate': 4.253075571177505e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1237, 'grad_norm': 0.06028518080711365, 'learning_rate': 4.077328646748682e-06, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0472, 'grad_norm': 1.7556403875350952, 'learning_rate': 3.9015817223198596e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 390/599 [04:56<02:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0702, 'grad_norm': 4.322009086608887, 'learning_rate': 3.725834797891037e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0545, 'grad_norm': 0.13014119863510132, 'learning_rate': 3.5500878734622145e-06, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 410/599 [05:11<02:22,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0818, 'grad_norm': 0.27187395095825195, 'learning_rate': 3.3743409490333924e-06, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0852, 'grad_norm': 0.18148881196975708, 'learning_rate': 3.19859402460457e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0496, 'grad_norm': 0.563698947429657, 'learning_rate': 3.022847100175747e-06, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 440/599 [05:34<02:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0862, 'grad_norm': 0.2017112672328949, 'learning_rate': 2.847100175746925e-06, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0824, 'grad_norm': 0.5419926643371582, 'learning_rate': 2.6713532513181023e-06, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0537, 'grad_norm': 0.1314176619052887, 'learning_rate': 2.4956063268892797e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0343, 'grad_norm': 0.7565054893493652, 'learning_rate': 2.319859402460457e-06, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 480/599 [06:04<01:30,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1003, 'grad_norm': 0.008058815263211727, 'learning_rate': 2.1441124780316347e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0912, 'grad_norm': 9.312235832214355, 'learning_rate': 1.968365553602812e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 500/599 [06:20<01:15,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0244, 'grad_norm': 0.8871272802352905, 'learning_rate': 1.7926186291739898e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/11/2025 08:59:52 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to ./model/checkpoint-500\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0929, 'grad_norm': 0.15945373475551605, 'learning_rate': 1.616871704745167e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1272, 'grad_norm': 1.56130850315094, 'learning_rate': 1.4411247803163445e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0831, 'grad_norm': 6.289640426635742, 'learning_rate': 1.2653778558875222e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 540/599 [06:53<00:44,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0687, 'grad_norm': 4.000422477722168, 'learning_rate': 1.0896309314586997e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0845, 'grad_norm': 0.5120553970336914, 'learning_rate': 9.138840070298771e-07, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0361, 'grad_norm': 0.1311747431755066, 'learning_rate': 7.381370826010545e-07, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0795, 'grad_norm': 0.04076971486210823, 'learning_rate': 5.62390158172232e-07, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1078, 'grad_norm': 5.393497943878174, 'learning_rate': 3.8664323374340953e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1366, 'grad_norm': 2.2181813716888428, 'learning_rate': 2.1089630931458702e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [07:37<00:00,  1.38it/s]07/11/2025 09:01:10 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to ./model/checkpoint-599\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 461.4716, 'train_samples_per_second': 25.96, 'train_steps_per_second': 1.298, 'train_loss': 0.11219942868253424, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [07:41<00:00,  1.30it/s]\n",
      "07/11/2025 09:01:14 - INFO - FlagEmbedding.finetune.embedder.encoder_only.base.trainer -   Saving model checkpoint to ./model\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[rank0]:[W711 09:01:16.012131013 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "torchrun --nproc_per_node 1 \\\n",
    "\t-m FlagEmbedding.finetune.embedder.encoder_only.base \\\n",
    "\t--model_name_or_path BAAI/bge-small-en-v1.5 \\\n",
    "    --train_data ./data/training.json \\\n",
    "    --query_instruction_for_retrieval 'Represent this sentence for searching relevant passages: ' \\\n",
    "\t--output_dir ./model \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --fp16 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size 20 \\\n",
    "    --query_max_len 256 \\\n",
    "    --passage_max_len 512 \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --normalize_embeddings True \\\n",
    "    --logging_steps 10 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9579b270-0775-41cc-8ded-bcf5989a7f70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T09:19:13.977377Z",
     "iopub.status.busy": "2025-07-11T09:19:13.977099Z",
     "iopub.status.idle": "2025-07-11T09:19:13.986060Z",
     "shell.execute_reply": "2025-07-11T09:19:13.985533Z",
     "shell.execute_reply.started": "2025-07-11T09:19:13.977359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/\n",
      "model/runs\n",
      "model/runs/Jul11_08-53-26_default\n",
      "model/checkpoint-599\n",
      "model/checkpoint-500\n",
      "model/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('model/'):\n",
    "    print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a00841cf-40a3-44b0-bea6-a964ab9374b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T09:20:17.584435Z",
     "iopub.status.busy": "2025-07-11T09:20:17.583968Z",
     "iopub.status.idle": "2025-07-11T09:20:19.122484Z",
     "shell.execute_reply": "2025-07-11T09:20:19.121891Z",
     "shell.execute_reply.started": "2025-07-11T09:20:17.584417Z"
    }
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('model/'):\n",
    "    if root=='model/':\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_path, 'model/')\n",
    "            s3_key = f\"finetuned_model/{relative_path}\"\n",
    "            boto3_client.upload_file(local_path, 'medical-qa-data', s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e045b7d-30c4-4b97-874d-212b33441719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T05:25:24.849125Z",
     "iopub.status.busy": "2025-07-11T05:25:24.848640Z",
     "iopub.status.idle": "2025-07-11T05:25:24.853913Z",
     "shell.execute_reply": "2025-07-11T05:25:24.853384Z",
     "shell.execute_reply.started": "2025-07-11T05:25:24.849107Z"
    }
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def search(model, queries_text, corpus_text):\n",
    "    \n",
    "    queries_embeddings = model.encode_queries(queries_text)\n",
    "    corpus_embeddings = model.encode_corpus(corpus_text)\n",
    "    \n",
    "    # create and store the embeddings in a Faiss index\n",
    "    dim = corpus_embeddings.shape[-1]\n",
    "    index = faiss.index_factory(dim, 'Flat', faiss.METRIC_INNER_PRODUCT)\n",
    "    corpus_embeddings = corpus_embeddings.astype(np.float32)\n",
    "    index.train(corpus_embeddings)\n",
    "    index.add(corpus_embeddings)\n",
    "    \n",
    "    query_size = len(queries_embeddings)\n",
    "\n",
    "    all_scores = []\n",
    "    all_indices = []\n",
    "\n",
    "    # search top 100 answers for all the queries\n",
    "    for i in tqdm(range(0, query_size, 32), desc=\"Searching\"):\n",
    "        j = min(i + 32, query_size)\n",
    "        query_embedding = queries_embeddings[i: j]\n",
    "        score, indice = index.search(query_embedding.astype(np.float32), k=20)\n",
    "        all_scores.append(score)\n",
    "        all_indices.append(indice)\n",
    "\n",
    "    all_scores = np.concatenate(all_scores, axis=0)\n",
    "    all_indices = np.concatenate(all_indices, axis=0)\n",
    "    \n",
    "    # store the results into the format for evaluation\n",
    "    results = {}\n",
    "    for idx, (scores, indices) in enumerate(zip(all_scores, all_indices)):\n",
    "        results[str(queries[\"id\"][idx])] = {}\n",
    "        for score, index in zip(scores, indices):\n",
    "            if index != -1:\n",
    "                results[str(queries[\"id\"][idx])][str(index)] = float(score)\n",
    "                \n",
    "    return results, corpus_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085784ac-4b8b-4c04-a202-22c5bcf6e9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T03:55:35.172395Z",
     "iopub.status.busy": "2025-07-11T03:55:35.171910Z",
     "iopub.status.idle": "2025-07-11T03:55:36.310189Z",
     "shell.execute_reply": "2025-07-11T03:55:36.309659Z",
     "shell.execute_reply.started": "2025-07-11T03:55:35.172377Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "queries = load_dataset(\"json\", data_files=\"data/test_queries.jsonl\")[\"train\"]\n",
    "corpus = load_dataset(\"json\", data_files=\"data/corpus.jsonl\")[\"train\"]\n",
    "qrels = load_dataset(\"json\", data_files=\"data/test_qrels.jsonl\")[\"train\"]\n",
    "\n",
    "queries_text = queries[\"text\"]\n",
    "corpus_text = [text for text in corpus[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7647f8f1-0747-4f3d-b43e-52514cfac0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T03:55:36.683811Z",
     "iopub.status.busy": "2025-07-11T03:55:36.683401Z",
     "iopub.status.idle": "2025-07-11T03:55:36.777009Z",
     "shell.execute_reply": "2025-07-11T03:55:36.776535Z",
     "shell.execute_reply.started": "2025-07-11T03:55:36.683794Z"
    }
   },
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "for line in qrels:\n",
    "    if line['qid'] not in qrels_dict:\n",
    "        qrels_dict[str(line['qid'])] = {}\n",
    "    for doc in line['docid']:\n",
    "        qrels_dict[str(line['qid'])][str(doc)] = line['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74576203-ce20-4049-a9d1-fde0432b2b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:43:00.564965Z",
     "iopub.status.busy": "2025-07-11T08:43:00.564174Z",
     "iopub.status.idle": "2025-07-11T08:43:00.567824Z",
     "shell.execute_reply": "2025-07-11T08:43:00.567292Z",
     "shell.execute_reply.started": "2025-07-11T08:43:00.564946Z"
    }
   },
   "outputs": [],
   "source": [
    "from FlagEmbedding.abc.evaluation.utils import evaluate_metrics, evaluate_mrr\n",
    "from FlagEmbedding import FlagModel\n",
    "\n",
    "k_values = [3, 5, 10]\n",
    "\n",
    "raw_name = \"BAAI/bge-large-en-v1.5\"\n",
    "finetuned_path = \"model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea408abb-f619-4fce-a5ca-75dcba8a666c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T03:56:44.733594Z",
     "iopub.status.busy": "2025-07-11T03:56:44.733055Z",
     "iopub.status.idle": "2025-07-11T03:58:14.279591Z",
     "shell.execute_reply": "2025-07-11T03:58:14.279056Z",
     "shell.execute_reply.started": "2025-07-11T03:56:44.733577Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18714596478c4393b9144d8707f3261a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c510b02ef644f49317a31542e10d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1093dd838d824173a24a609fa2932c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d65b91611f0486bb6cf5eea157941d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3990eb921f4433b4beb4d49b056407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba7aac083da4f18bd85e25e3cd5ff3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 12/12 [00:00<00:00, 207.95it/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 12/12 [00:00<00:00, 16.97it/s]\n",
      "pre tokenize: 100%|██████████| 74/74 [00:04<00:00, 14.83it/s]\n",
      "Inference Embeddings: 100%|██████████| 74/74 [01:03<00:00,  1.16it/s]\n",
      "Searching: 100%|██████████| 94/94 [00:01<00:00, 63.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'NDCG@3': 0.71055, 'NDCG@5': 0.73125, 'NDCG@10': 0.74665})\n",
      "defaultdict(<class 'list'>, {'MAP@3': 0.66256, 'MAP@5': 0.67955, 'MAP@10': 0.68967})\n",
      "defaultdict(<class 'list'>, {'Recall@3': 0.76479, 'Recall@5': 0.82027, 'Recall@10': 0.86819})\n",
      "defaultdict(<class 'list'>, {'P@3': 0.30307, 'P@5': 0.2004, 'P@10': 0.10938})\n",
      "defaultdict(<class 'list'>, {'MRR@3': 0.71913, 'MRR@5': 0.73032, 'MRR@10': 0.73552})\n"
     ]
    }
   ],
   "source": [
    "raw_model = FlagModel(\n",
    "    raw_name, \n",
    "    query_instruction_for_retrieval=\"\",\n",
    "    devices=[0],\n",
    "    use_fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "results, _ = search(raw_model, queries_text, corpus_text)\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f464f3a-4523-404d-bf2c-e7f08bb8a676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:43:12.180489Z",
     "iopub.status.busy": "2025-07-11T08:43:12.180118Z",
     "iopub.status.idle": "2025-07-11T08:43:13.614441Z",
     "shell.execute_reply": "2025-07-11T08:43:13.613765Z",
     "shell.execute_reply.started": "2025-07-11T08:43:12.180471Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ft_model = FlagModel(\n",
    "    finetuned_path, \n",
    "    query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "    devices=[0],\n",
    "    use_fp16=True\n",
    ")\n",
    "\n",
    "results, corpus_embeddings = search(ft_model, queries_text, corpus_text)\n",
    "\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "18be22ef-8276-4eac-ab2e-789a625286ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:11:12.654675Z",
     "iopub.status.busy": "2025-07-11T08:11:12.654142Z",
     "iopub.status.idle": "2025-07-11T08:11:12.667561Z",
     "shell.execute_reply": "2025-07-11T08:11:12.666963Z",
     "shell.execute_reply.started": "2025-07-11T08:11:12.654656Z"
    }
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "\n",
    "host = 'search-medical-qa-system-wllp2yik3gws7durfruiomvfky.us-east-2.es.amazonaws.com'  \n",
    "region = 'us-east-2'\n",
    "\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "# create an opensearch client and use the request-signer\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    pool_maxsize=20,\n",
    "    vector_field='vector_field'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333c0395-857d-433a-bb20-ba0b1da65d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:48:43.397759Z",
     "iopub.status.busy": "2025-07-11T08:48:43.397298Z",
     "iopub.status.idle": "2025-07-11T08:48:43.996146Z",
     "shell.execute_reply": "2025-07-11T08:48:43.995596Z",
     "shell.execute_reply.started": "2025-07-11T08:48:43.397741Z"
    }
   },
   "outputs": [],
   "source": [
    "ft_model.model.save_pretrained('.trained_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d287f13e-6d1b-4310-821f-91bbcf004da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:11:16.020761Z",
     "iopub.status.busy": "2025-07-11T08:11:16.020446Z",
     "iopub.status.idle": "2025-07-11T08:11:16.723484Z",
     "shell.execute_reply": "2025-07-11T08:11:16.722875Z",
     "shell.execute_reply.started": "2025-07-11T08:11:16.020744Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"settings\": {\n",
    "    \"index.knn\": True\n",
    "  },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"chunk\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"standard\"\n",
    "            },\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 384,\n",
    "                \"method\": {\n",
    "                  \"name\": \"hnsw\",\n",
    "                  \"space_type\": \"l2\",\n",
    "                  \"engine\": \"faiss\"\n",
    "                }\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "index_name = 'embedding-finetuned-v1'\n",
    "create_response = client.indices.create(\n",
    "    index=index_name,\n",
    "    body=mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "2eea0000-58d7-4217-950c-34c3dca9a238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:11:21.954497Z",
     "iopub.status.busy": "2025-07-11T08:11:21.954094Z",
     "iopub.status.idle": "2025-07-11T08:12:21.191876Z",
     "shell.execute_reply": "2025-07-11T08:12:21.191375Z",
     "shell.execute_reply.started": "2025-07-11T08:11:21.954481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18802it [00:00, 304072.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 18802 documents\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy.helpers import bulk\n",
    "from tqdm import tqdm\n",
    "\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": \"embedding-finetuned-v1\",\n",
    "        \"_source\": {\n",
    "            \"chunk\": text,\n",
    "            \"vector_field\": emb\n",
    "        }\n",
    "    }\n",
    "    for text, emb in tqdm(zip(corpus_text, corpus_embeddings.tolist()))\n",
    "]\n",
    "\n",
    "success, _ = bulk(client, actions, request_timeout=240)\n",
    "print(f\"Successfully indexed {success} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e2919e78-bfc5-4736-b8f9-6d63e8040510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:13:28.102116Z",
     "iopub.status.busy": "2025-07-11T08:13:28.101770Z",
     "iopub.status.idle": "2025-07-11T08:13:28.124912Z",
     "shell.execute_reply": "2025-07-11T08:13:28.124436Z",
     "shell.execute_reply.started": "2025-07-11T08:13:28.102099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".plugins-ml-config open 1\n",
      ".opensearch-observability open 0\n",
      "embedding-finetuned-v1 open 14116\n",
      ".kibana_1 open 1\n"
     ]
    }
   ],
   "source": [
    "indices = client.cat.indices(format=\"json\")\n",
    "for idx in indices:\n",
    "    print(idx['index'], idx['status'], idx['docs.count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6e68d4ec-bbf9-4c67-a887-0891d965dfb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:14:47.636408Z",
     "iopub.status.busy": "2025-07-11T08:14:47.635989Z",
     "iopub.status.idle": "2025-07-11T08:14:47.639031Z",
     "shell.execute_reply": "2025-07-11T08:14:47.638498Z",
     "shell.execute_reply.started": "2025-07-11T08:14:47.636391Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://search-medical-qa-system-wllp2yik3gws7durfruiomvfky.us-east-2.es.amazonaws.com/embedding-finetuned-v1/_search' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9b2e5e9-e1c8-4846-9211-e635341d2024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T09:39:26.420395Z",
     "iopub.status.busy": "2025-07-11T09:39:26.419858Z",
     "iopub.status.idle": "2025-07-11T09:39:26.439099Z",
     "shell.execute_reply": "2025-07-11T09:39:26.438322Z",
     "shell.execute_reply.started": "2025-07-11T09:39:26.420376Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[43mcorpus_embeddings\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m   }\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m     15\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://search-medical-qa-system-wllp2yik3gws7durfruiomvfky.us-east-2.es.amazonaws.com/embedding-finetuned-v1/_search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     json\u001b[38;5;241m=\u001b[39mquery,  \u001b[38;5;66;03m# ✅ Proper serialization\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m     18\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# ✅ Required header\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "query_vector = corpus_embeddings[0].tolist()\n",
    "\n",
    "query = {\n",
    "  \"query\": {\n",
    "    \"knn\": {\n",
    "      \"vector_field\": {\n",
    "        \"vector\": query_vector,\n",
    "        \"k\": 3\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    url=\"https://search-medical-qa-system-wllp2yik3gws7durfruiomvfky.us-east-2.es.amazonaws.com/embedding-finetuned-v1/_search\",\n",
    "    json=query,  # ✅ Proper serialization\n",
    "    auth=auth,\n",
    "    headers={\"Content-Type\": \"application/json\"}  # ✅ Required header\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "07a4e84f-e06a-4989-9c95-effb965a194d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:16:02.698635Z",
     "iopub.status.busy": "2025-07-11T08:16:02.698320Z",
     "iopub.status.idle": "2025-07-11T08:16:02.702494Z",
     "shell.execute_reply": "2025-07-11T08:16:02.701998Z",
     "shell.execute_reply.started": "2025-07-11T08:16:02.698618Z"
    }
   },
   "outputs": [],
   "source": [
    "r = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "2b003999-7241-47c5-99cf-84e4cf1a6e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T08:17:19.351978Z",
     "iopub.status.busy": "2025-07-11T08:17:19.351542Z",
     "iopub.status.idle": "2025-07-11T08:17:19.355667Z",
     "shell.execute_reply": "2025-07-11T08:17:19.355118Z",
     "shell.execute_reply.started": "2025-07-11T08:17:19.351961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Glaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. The most common form of the disease is open-angle glaucoma. With early treatment, you can often protect your eyes against serious vision loss. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.)  See this graphic for a quick overview of glaucoma, including how many people it affects, whos at risk, what to do if you have it, and how to learn more.  See a glossary of glaucoma terms.\",\n",
       " \"Glaucoma is a group of diseases that can damage the eye's optic nerve. It is a leading cause of blindness in the United States. It usually happens when the fluid pressure inside the eyes slowly rises, damaging the optic nerve. Often there are no symptoms at first. Without treatment, people with glaucoma will slowly lose their peripheral, or side vision. They seem to be looking through a tunnel. Over time, straight-ahead vision may decrease until no vision remains.    A comprehensive eye exam can tell if you have glaucoma. People at risk should get eye exams at least every two years. They include       -  African Americans over age 40    -  People over age 60, especially Mexican Americans    -  People with a family history of glaucoma       There is no cure, but glaucoma can usually be controlled. Early treatment can help protect your eyes against vision loss. Treatments usually include prescription eyedrops and/or surgery.    NIH: National Eye Institute\",\n",
       " 'Glaucoma is a group of eye disorders in which the optic nerves connecting the eyes and the brain are progressively damaged. This damage can lead to reduction in side (peripheral) vision and eventual blindness. Other signs and symptoms may include bulging eyes, excessive tearing, and abnormal sensitivity to light (photophobia). The term \"early-onset glaucoma\" may be used when the disorder appears before the age of 40.  In most people with glaucoma, the damage to the optic nerves is caused by increased pressure within the eyes (intraocular pressure). Intraocular pressure depends on a balance between fluid entering and leaving the eyes.  Usually glaucoma develops in older adults, in whom the risk of developing the disorder may be affected by a variety of medical conditions including high blood pressure (hypertension) and diabetes mellitus, as well as family history. The risk of early-onset glaucoma depends mainly on heredity.  Structural abnormalities that impede fluid drainage in the eye may be present at birth and usually become apparent during the first year of life. Such abnormalities may be part of a genetic disorder that affects many body systems, called a syndrome. If glaucoma appears before the age of 5 without other associated abnormalities, it is called primary congenital glaucoma.  Other individuals experience early onset of primary open-angle glaucoma, the most common adult form of glaucoma. If primary open-angle glaucoma develops during childhood or early adulthood, it is called juvenile open-angle glaucoma.',\n",
       " 'Open-angle glaucoma is the most common form of glaucoma. In the normal eye, the clear fluid leaves the anterior chamber at the open angle where the cornea and iris meet. When the fluid reaches the angle, it flows through a spongy meshwork, like a drain, and leaves the eye. Sometimes, when the fluid reaches the angle, it passes too slowly through the meshwork drain, causing the pressure inside the eye to build. If the pressure damages the optic nerve, open-angle glaucoma -- and vision loss -- may result.',\n",
       " 'Anyone can develop glaucoma. Some people are at higher risk than others. They include - African-Americans over age 40  - everyone over age 60, especially Hispanics/Latinos  - people with a family history of glaucoma. African-Americans over age 40 everyone over age 60, especially Hispanics/Latinos people with a family history of glaucoma.  See this graphic for a quick overview of glaucoma, including how many people it affects, whos at risk, what to do if you have it, and how to learn more.',\n",
       " \"Yes. Immediate treatment for early stage, open-angle glaucoma can delay progression of the disease. That's why early diagnosis is very important. Glaucoma treatments include medicines, laser surgery, conventional surgery, or a combination of any of these. While these treatments may save remaining vision, they do not improve sight already lost from glaucoma.\",\n",
       " 'At this time, we do not know how to prevent glaucoma. However, studies have shown that the early detection and treatment of glaucoma, before it causes major vision loss, is the best way to control the disease. So, if you fall into one of the higher risk groups for the disease, make sure to have a comprehensive dilated eye exam at least once every one to two years.  Get tips on finding an eye care professional. Learn what a comprehensive dilated eye exam involves.',\n",
       " 'At first, open-angle glaucoma has no symptoms. It causes no pain. Vision seems normal. Without treatment, people with glaucoma will slowly lose their peripheral, or side vision. They seem to be looking through a tunnel. Over time, straight-ahead vision may decrease until no vision remains.',\n",
       " 'Primary congenital glaucoma affects approximately 1 in 10,000 people. Its frequency is higher in the Middle East. Juvenile open-angle glaucoma affects about 1 in 50,000 people. Primary open-angle glaucoma is much more common after the age of 40, affecting about 1 percent of the population worldwide.',\n",
       " \"Encourage them to have a comprehensive dilated eye exam at least once every two years. Remember -- lowering eye pressure in glaucoma's early stages slows progression of the disease and helps save vision.  Get tips on finding an eye care professional.\"]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hit['_source']['chunk'] for hit in r['hits']['hits']]"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
