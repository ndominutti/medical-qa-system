{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa6fe39",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline\n",
    "\n",
    "This is the first step of our workflow, the preprocessing pipeline. Here, I will wrangle the data and then load it into an S3 bucket to be used by our fine-tuning job.\n",
    "\n",
    "I will be using the FlagEmbedding library to fine-tune the bge-base-en-v1.5 model. For this, a specific dataframe shape is required:\n",
    "\n",
    "```\n",
    "\n",
    "{\"query\": str, \"pos\": List[str], \"neg\":List[str]}\n",
    "\n",
    "```\n",
    "\n",
    "Moreover, for performance validation, I will also need to save three JSON files:\n",
    "1. Validation queries\n",
    "2. Query-to-positive mapping\n",
    "3. The entire answers corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2599b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r data_processing/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a518b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d943557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from general_utils import load_config\n",
    "import torch\n",
    "\n",
    "load_dotenv(\"data_processing/.env\")\n",
    "CONFIG = load_config()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc33055",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e4efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_processing/data/intern_screening_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929070a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have null answers (5)\n",
    "df = df[~df.answer.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5eb687",
   "metadata": {},
   "source": [
    "## Text cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d08b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition of \"(are)\", like in What is (are) Hyperthyroidism ?\n",
    "df.loc[:, 'question'] = df['question'].apply(lambda q: q.replace(\"(are)\", \"\").replace('? ?','?').strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b96f6",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "While I was exploring the dataset, I discovered that some questions are too long to be utilized to fine-tune a bge-base-en-v1.5 model, that's why I would chunk them to avoid loosing information at fine-tuning time (and also at embedding and saving time to the vector DB).\n",
    "For this, I will:\n",
    "* use the llama-index's sentence splitter provides a quick way to chunk text while preserving the structure, such as paragraphs and sentences\n",
    "* bring the bge-base-en-1.5 tokenizer to provide the tokens countig to the chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ab0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36bcc848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolas.dominutti/Desktop/ml/medical-qa-system/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"BAAI/{CONFIG['EMBEDDING_MODEL']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f73b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(\n",
    "    chunk_size=CONFIG['CHUNK_MAX_LENGTH'],\n",
    "    tokenizer=tokenizer.tokenize,\n",
    "    chunk_overlap=CONFIG['CHUNK_OVERLAP'],\n",
    "    separator=\".\",\n",
    "    paragraph_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48979a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#Here I apply the splitter and then explode the rows to have 1 row per chunk\n",
    "df.loc[:, 'answer'] = df['answer'].apply(lambda ans: splitter.split_text(ans))\n",
    "df = df.explode('answer').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ebc9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous: (20053, 2)\n",
      "after: (19944, 2)\n"
     ]
    }
   ],
   "source": [
    "#remove some duplicates in question-answer pairs\n",
    "print(f\"previous: {df.shape}\")\n",
    "df = df.drop_duplicates(subset=['question', 'answer'])\n",
    "print(f\"after: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcc94b",
   "metadata": {},
   "source": [
    "### Training Triplets\n",
    "To fine-tune the embedding model, I will adopt a *contrastive learning approach*, where the task during training is to bring positive samples closer than negative ones.\n",
    "\n",
    "For that purpose, I currently have a dataset of Q–Positive chunks, but I still need to create the *negative samples*. There are different ways to do this, with the most effective being hard negative mining (selecting chunks that are similar to the positive ones to make the task more challenging for the model). However, for the sake of time, I won’t be using hard negative mining and will instead select negative samples at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e34a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.utils import TripletsMiner\n",
    "tm = TripletsMiner(CONFIG['RANDOM_SEED'])\n",
    "negatives = tm.get_negatives(df, 'soft', CONFIG['NEGATIVES_N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb9221",
   "metadata": {},
   "source": [
    "### Handling the queries repetition and IDs tracking\n",
    "\n",
    "In the original dataset, there were cases where the same query appeared in multiple rows with different answers. Since I further chunked the answers, this now happens even more often. Given the structure required by the FlagEmbedding library, I need to keep track of one ID for unique questions and another for unique chunks. To do this, I create two mapping tables that I then join with the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc73b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_questions = pd.DataFrame(df.question.unique(), columns=['question']).reset_index(names='question_id')\n",
    "unique_answers = pd.DataFrame(df.answer.unique(), columns=['answer']).reset_index(names='chunk_id')\n",
    "\n",
    "df = df.merge(\n",
    "    unique_answers,\n",
    "    how='left',\n",
    "    on='answer',\n",
    ")\n",
    "\n",
    "df = df.merge(\n",
    "    unique_questions,\n",
    "    how='left',\n",
    "    on='question',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2c3de",
   "metadata": {},
   "source": [
    "Now, to continue shaping the dataframe, I will generate a list of positive chunks for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965b4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_gen = df.groupby(['question_id','question'])\n",
    "#create the lists separatedly as I need to keep track of the chunks ids\n",
    "df = gb_gen['answer'].apply(list).reset_index()\n",
    "chunks = gb_gen['chunk_id'].apply(list).reset_index()\n",
    "df['neg'] = negatives\n",
    "df = df.merge(chunks[['question_id','chunk_id']], on='question_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4bb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming to respect what FlagEmbeddings needs\n",
    "df = df.rename(columns={'answer': 'pos'})\n",
    "df = df.rename(columns={'question': 'query'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b25db",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491acf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I create the train-test dataset and proceed to save the trianing one\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "splits = dataset.train_test_split(test_size=CONFIG['TEST_DATA_FRAC'], seed=CONFIG['RANDOM_SEED'])\n",
    "train_df = splits['train']\n",
    "val_df = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "658f13bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 12/12 [00:02<00:00,  4.40ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "219285853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.to_json(\"data/training.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ba808",
   "metadata": {},
   "source": [
    "### Validation dataset\n",
    "\n",
    "For training validation I will need to save:\n",
    "\n",
    "1. The validation queries\n",
    "2. The whole corpus (so at validation time I can embed it an index for retrieval) \n",
    "3. A dictionary mapping the query_id to the positive chunks ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d6dc4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 12782,\n",
       " 'text': 'How many people are affected by von Hippel-Lindau syndrome ?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = val_df.select_columns(column_names=[\"question_id\", \"query\"])\n",
    "queries = queries.rename_columns({\"query\": \"text\", \"question_id\": \"id\"})\n",
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a82ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'text': \"Glaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. The most common form of the disease is open-angle glaucoma. With early treatment, you can often protect your eyes against serious vision loss. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.)  See this graphic for a quick overview of glaucoma, including how many people it affects, whos at risk, what to do if you have it, and how to learn more.  See a glossary of glaucoma terms.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Dataset.from_pandas(unique_answers, preserve_index=False)\n",
    "corpus = corpus.select_columns(column_names=[\"chunk_id\", \"answer\"])\n",
    "corpus = corpus.rename_columns({\"answer\": \"text\", \"chunk_id\": \"id\"})\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df63d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 2996/2996 [00:00<00:00, 167439.07 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'qid': 12782, 'docid': [15877], 'relevance': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = val_df.select_columns([\"question_id\"])\n",
    "qrels = qrels.rename_column(\"question_id\", \"qid\")\n",
    "qrels = qrels.add_column(\"docid\", list(val_df[\"chunk_id\"]))\n",
    "qrels = qrels.add_column(\"relevance\", [1]*len(list(val_df[\"chunk_id\"])))\n",
    "qrels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7449cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 86.77ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 19/19 [00:00<00:00, 90.15ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 503.72ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133606"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.to_json(\"data/test_queries.jsonl\")\n",
    "corpus.to_json(\"data/corpus.jsonl\")\n",
    "qrels.to_json(\"data/test_qrels.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0c683",
   "metadata": {},
   "source": [
    "### Saving to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa5e60",
   "metadata": {},
   "source": [
    "To complete the work in this notebook, I will save the artifacts to S3, simulating execution within a pipeline service. This ensures the data is ready to be ingested on a GPU-enabled machine for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23307126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_utils import S3Manager\n",
    "s3_client = S3Manager.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3352fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3Manager.upload_bulk(s3_client, 'data/', [\"training.json\", \"test_queries.jsonl\", \"corpus.jsonl\", \"test_qrels.jsonl\"], CONFIG['S3_BUCKET'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
